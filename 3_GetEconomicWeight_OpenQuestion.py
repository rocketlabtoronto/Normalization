#!/usr/bin/env python3
"""
Get economic weights for dual class companies by directly querying OpenAI about their share class information.
This script takes the dual_class_output.json and enriches it with economic weight data using AI queries.
This is a token-efficient alternative to 3_GetEconomicWeight.py that avoids downloading SEC filings.
"""

import os
import json
import re
import requests
import time
from typing import List, Dict, Any, Optional
from dataclasses import dataclass
import sys

# Attempt to load .env if python-dotenv is installed
try:  # optional
    from dotenv import load_dotenv  # type: ignore
    load_dotenv()
except Exception:
    pass

# Manual fallback .env loader if OPENAI_API_KEY still unset
if not os.getenv("OPENAI_API_KEY") and os.path.exists(".env"):
    try:
        with open(".env", "r", encoding="utf-8") as _f:
            for _ln in _f:
                if not _ln.strip() or _ln.strip().startswith("#"):
                    continue
                if "=" in _ln:
                    k, v = _ln.split("=", 1)
                    k = k.strip()
                    v = v.strip().strip('"').strip("'")
                    if k and v and k not in os.environ:
                        os.environ[k] = v
    except Exception:
        pass

@dataclass
class EconomicWeight:
    """Data structure for economic weight information"""
    class_name: str
    ticker: str = ""
    shares_outstanding: Optional[float] = None
    economic_weight: Optional[float] = None  # Proportion of total economic value (0.0 to 1.0)
    conversion_ratio: Optional[float] = None  # How many units of primary class this represents
    votes_per_share: Optional[float] = None  # Voting power per share
    source: str = ""  # Source of the data (AI query, etc.)
    ticker_source: Optional[str] = None  # Where the ticker came from

def fetch_sec_cik_map() -> Dict[str, str]:
    """Fetch SEC ticker to CIK mapping."""
    url = "https://www.sec.gov/files/company_tickers.json"
    headers = {'User-Agent': 'Economic Weight Analysis Tool (contact@example.com)'}
    
    try:
        response = requests.get(url, headers=headers, timeout=30)
        response.raise_for_status()
        data = response.json()
        
        ticker_map = {}
        for entry in data.values():
            ticker = entry.get('ticker', '').upper()
            cik = entry.get('cik_str') or str(entry.get('cik', ''))
            if ticker and cik:
                # Format CIK with leading zeros
                ticker_map[ticker] = f"{int(cik):010d}"
        
        return ticker_map
    except Exception as e:
        print(f"Warning: Could not fetch SEC data: {e}")
        return {}

def investigate_no_cik_with_ai(company_name: str, primary_ticker: str) -> Dict[str, Any]:
    """Use AI to investigate why a company has no CIK - likely delisted, acquired, or name change"""
    api_key = os.getenv('OPENAI_API_KEY')
    model = os.getenv('LLM_MODEL', 'gpt-4o')
    
    if not api_key:
        return {"status": "unknown", "reason": "No API key"}
    
    prompt = f"""Investigate why {company_name} (ticker: {primary_ticker}) cannot be found in SEC CIK database.

This usually happens when companies are:
1. DELISTED from stock exchanges
2. ACQUIRED by other companies
3. MERGED with other entities
4. WENT BANKRUPT/LIQUIDATED
5. CHANGED COMPANY NAME significantly

Please research and determine what happened to this company. Return ONLY JSON:

{{
  "status": "delisted" | "acquired" | "merged" | "bankrupt" | "name_changed" | "unknown",
  "reason": "Brief explanation of what happened",
  "acquirer": "Name of acquiring company if applicable",
  "date": "Approximate date if known",
  "still_active": true/false
}}

Company: {company_name} ({primary_ticker})"""

    try:
        try:
            import openai  # type: ignore
        except ImportError:
            return {"status": "unknown", "reason": "OpenAI not available"}

        if hasattr(openai, 'OpenAI'):
            client = openai.OpenAI(api_key=api_key)
            response = client.chat.completions.create(
                model=model,
                messages=[
                    {"role": "system", "content": "You are a financial research analyst. Return ONLY JSON as specified."},
                    {"role": "user", "content": prompt}
                ],
                max_tokens=300,
                temperature=0.1
            )
            result = response.choices[0].message.content if response.choices else ''
        else:
            openai.api_key = api_key
            response = openai.ChatCompletion.create(
                model=model,
                messages=[
                    {"role": "system", "content": "You are a financial research analyst. Return ONLY JSON as specified."},
                    {"role": "user", "content": prompt}
                ],
                max_tokens=300,
                temperature=0.1
            )
            result = response['choices'][0]['message']['content']

        # Parse AI response
        if result:
            # Clean JSON
            cleaned = result.strip()
            if cleaned.startswith('```json'):
                cleaned = cleaned[7:]
            if cleaned.startswith('```'):
                cleaned = cleaned[3:]
            if cleaned.endswith('```'):
                cleaned = cleaned[:-3]
            cleaned = cleaned.strip()
            
            # Extract JSON
            if '{' in cleaned:
                start = cleaned.find('{')
                brace = 0
                end = -1
                for i, ch in enumerate(cleaned[start:], start=start):
                    if ch == '{':
                        brace += 1
                    elif ch == '}':
                        brace -= 1
                        if brace == 0:
                            end = i + 1
                            break
                if end != -1:
                    candidate = cleaned[start:end]
                else:
                    candidate = cleaned[start:]
                
                import json
                data = json.loads(candidate)
                return data
        
        return {"status": "unknown", "reason": "Could not parse AI response"}
        
    except Exception as e:
        print(f"    ‚ùå AI investigation failed: {e}")
        return {"status": "unknown", "reason": f"Error: {e}"}

def lookup_cik_by_name_or_ticker(company_name: str, primary_ticker: str, ticker_map: Dict[str, str]) -> Optional[str]:
    """Lookup CIK using company name or ticker with SEC API"""
    # First try the ticker map
    if primary_ticker and primary_ticker.upper() in ticker_map:
        cik = ticker_map[primary_ticker.upper()]
        print(f"    ‚úÖ Found CIK via ticker {primary_ticker}: {cik}")
        return cik
    
    # For well-known companies, try common ticker variants
    if company_name and 'berkshire' in company_name.lower():
        for variant in ['BRK.A', 'BRK.B', 'BRK-A', 'BRK-B']:
            if variant in ticker_map:
                cik = ticker_map[variant]
                print(f"    ‚úÖ Found Berkshire CIK via {variant}: {cik}")
                return cik
    
    # Try SEC company search API
    headers = {'User-Agent': 'Economic Weight Analysis Tool (contact@example.com)'}
    
    # Search by company name
    if company_name:
        try:
            search_url = "https://www.sec.gov/files/company_tickers.json"
            response = requests.get(search_url, headers=headers, timeout=30)
            response.raise_for_status()
            data = response.json()
            
            # Search through company titles
            for entry in data.values():
                title = entry.get('title', '').lower()
                if company_name.lower() in title or title in company_name.lower():
                    cik = entry.get('cik_str') or str(entry.get('cik', ''))
                    if cik:
                        formatted_cik = f"{int(cik):010d}"
                        print(f"    ‚úÖ Found CIK via company name search: {formatted_cik}")
                        return formatted_cik
        except Exception as e:
            print(f"    ‚Üí Company name search failed: {e}")
    
    print(f"    ‚ùå Could not find CIK for {company_name} ({primary_ticker})")
    return None

def query_ai_for_economic_weights(company_name: str, ticker: str, cik: str, existing_classes: List[Dict]) -> List[EconomicWeight]:
    """Query OpenAI for economic weight information based on existing class structure
    This approach enriches known classes rather than trying to discover them from scratch.
    """
    api_key = os.getenv('OPENAI_API_KEY')
    model = os.getenv('LLM_MODEL', 'gpt-4o')

    if not api_key:
        print(f"    ‚ùå OPENAI_API_KEY not set, skipping AI analysis")
        return []

    print(f"    ü§ñ Querying AI for specific share class information...")
    
    # Build class context from existing data
    class_context = []
    for cls in existing_classes:
        class_name = cls.get('class_name', '')
        votes = cls.get('votes_per_share', 'unknown')
        class_context.append(f"- {class_name}: {votes} votes per share")
    
    class_info = "\n".join(class_context)
    
    prompt = f"""You are analyzing the dual-class share structure for {company_name} (ticker: {ticker}, CIK: {cik}).

I already know this company has these share classes:
{class_info}

Research this company's MOST RECENT quarterly earnings report (Q1 2025, Q4 2024, etc.) and provide the exact share class data for these specific classes.

Return ONLY JSON in this exact format (no markdown, no commentary):

{{
  "classes": [
    {{
      "class_name": "EXACT_CLASS_NAME_FROM_LIST_ABOVE",
      "ticker": "EXACT_TICKER" or "" if not publicly traded,
      "ticker_source": "known publicly traded" or "not traded",
      "shares_outstanding": number (exact shares from latest 10-Q/10-K),
      "conversion_ratio": number (economic conversion ratio - NEVER null),
      "votes_per_share": number (votes per share),
      "is_publicly_traded": true or false
    }}
  ]
}}

CRITICAL RESEARCH INSTRUCTIONS:
1. SEARCH FOR LATEST QUARTERLY DATA (March 2025, December 2024, etc.):
   - Look for the most recent 10-Q filing data in your knowledge base
   - Find "shares issued and outstanding" or "outstanding shares" 
   - Use EXACT numbers from the latest quarterly report

2. PROVIDE DATA FOR ALL CLASSES LISTED ABOVE:
   - For A.O. Smith specifically: "Class A Common" AND "Common" are separate classes
   - Class A Common Stock: ~1 vote per share, $5 par value
   - Common Stock: ~0.1 vote per share, $1 par value
   - Total shares should be ~141-142 million (not 152 million)

3. STANDARDIZE class_name to match the input:
   - Use the class names from the list above
   - "Class A Common: 1" ‚Üí "Class A Common"
   - "Common: 1/10" ‚Üí "Common"

4. TICKER SYMBOLS - Use your knowledge of actual trading symbols:
   - For publicly traded classes, provide the exact ticker symbol
   - If a class is not publicly traded, set ticker: ""
   - Many dual-class structures have only one publicly traded class

5. CONVERSION RATIO - ECONOMIC EQUIVALENCE (NEVER NULL):
   - If shares have equal economic rights (dividends, liquidation): set to 1 for both classes
   - If Class A converts to X Class B shares: Class A = X, Class B = 1
   - For equal economic rights: Class A: 1, Class B: 1
   - For Berkshire style: Class A: 1500, Class B: 1
   - NEVER use null - always provide a number

6. VOTING RIGHTS: Provide exact voting power per share
   - CRITICAL: Research and verify the EXACT voting structure from your authoritative knowledge base
   - DO NOT simply copy the voting data I provided - it may be incorrect
   - Verify voting ratios are mathematically consistent with known dual-class structures
   - Look for fractional voting patterns: 1, 10, 0.1, 0.0001, etc.
   - Use your comprehensive financial knowledge to provide accurate voting ratios
   - If you know the correct voting structure differs from what I provided, use your knowledge
   - Never leave votes_per_share as null

FIND THE MOST RECENT QUARTERLY REPORT DATA FOR ACCURATE OUTSTANDING SHARES FOR ALL CLASSES LISTED.

Company: {company_name} (Primary ticker: {ticker})
Known classes to research: {len(existing_classes)}"""

    try:
        try:
            import openai  # type: ignore
        except ImportError:
            print(f"    ‚ùå openai package not installed, skipping AI analysis")
            return []

        result: Optional[str] = None
        last_error: Optional[Exception] = None
        
        for attempt in range(1, 4):  # 3 attempts with retry
            try:
                print(f"    üì° Calling OpenAI API attempt {attempt}/3 ({model})...")
                if hasattr(openai, 'OpenAI'):
                    client = openai.OpenAI(api_key=api_key)
                    response = client.chat.completions.create(
                        model=model,
                        messages=[
                            {"role": "system", "content": "You are an expert financial analyst with knowledge of dual-class share structures. Return ONLY strict JSON as specified."},
                            {"role": "user", "content": prompt}
                        ],
                        max_tokens=1000,
                        temperature=0.1
                    )
                    result = response.choices[0].message.content if response.choices else ''
                else:
                    openai.api_key = api_key  # type: ignore
                    response = openai.ChatCompletion.create(  # type: ignore
                        model=model,
                        messages=[
                            {"role": "system", "content": "You are an expert financial analyst with knowledge of dual-class share structures. Return ONLY strict JSON as specified."},
                            {"role": "user", "content": prompt}
                        ],
                        max_tokens=1000,
                        temperature=0.1
                    )
                    result = response['choices'][0]['message']['content'] if response.get('choices') else ''  # type: ignore
                
                if not result or not str(result).strip():
                    raise ValueError('Empty LLM response')
                
                result = result.strip()
                preview = result[:120].replace('\n', ' ')
                print(f"    ‚úÖ Received response ({len(result)} chars) | preview: {preview}...")
                
                # Parse the JSON response
                parsed_weights = _parse_ai_json_to_weights(result, company_name, ticker)
                if parsed_weights is not None:
                    return parsed_weights
                else:
                    raise ValueError('JSON parse failed after extraction logic')
                    
            except Exception as e:
                last_error = e
                print(f"    ‚ö†Ô∏è Attempt {attempt} failed: {e}")
                if attempt < 3:
                    sleep_for = 1.5 * attempt
                    print(f"    ‚è≥ Backoff {sleep_for:.1f}s before retry...")
                    time.sleep(sleep_for)
                continue
        
        print(f"    ‚ùå All AI attempts failed: {last_error}")
        return []
        
    except Exception as outer:
        print(f"Warning: AI analysis failed for {company_name}: {outer}")
        return []

def _standardize_class_name(raw_name: str) -> str:
    """Standardize class names while preserving important distinctions like 'Class A Common' vs 'Common'"""
    if not raw_name:
        return "Class A"  # Default fallback
    
    import re
    
    # Handle original input format with voting descriptions
    if ':' in raw_name:
        base_name = raw_name.split(':', 1)[0].strip()
    else:
        base_name = raw_name.strip()
    
    # Preserve A.O. Smith style naming
    if 'class a common' in base_name.lower():
        return "Class A Common"
    if base_name.lower() in ['common', 'common stock'] or base_name.lower().startswith('common'):
        return "Common"
    
    # Handle "Class A Common Stock" pattern - extract just "Class A"
    match = re.search(r'Class\s+([A-Z])\s+Common\s+Stock', base_name, re.IGNORECASE)
    if match:
        letter = match.group(1).upper()
        return f"Class {letter}"
    
    # Extract the class letter using regex for standard patterns
    # Look for patterns like "Class A", "Class B:", "Class A Common", etc.
    match = re.search(r'Class\s+([A-Z])', base_name, re.IGNORECASE)
    if match:
        letter = match.group(1).upper()
        return f"Class {letter}"
    
    # Handle preferred stock
    if 'preferred' in base_name.lower():
        return "Preferred Stock"
    
    # Fallback: look for single letters that might indicate class
    match = re.search(r'\b([A-Z])\b', base_name)
    if match:
        letter = match.group(1).upper()
        return f"Class {letter}"
    
    # Final fallback based on common terms
    if 'common' in base_name.lower():
        return "Common"
    elif 'b' in base_name.lower():
        return "Class B"
    else:
        return "Class A"

def _clean_ticker_by_trading_status(ticker: str, is_publicly_traded: bool) -> str:
    """Return empty string for non-traded securities, clean ticker otherwise"""
    if not is_publicly_traded:
        return ""
    return ticker.strip() if ticker else ""

def _parse_ai_json_to_weights(raw: str, company_name: str, primary_ticker: str) -> Optional[List[EconomicWeight]]:
    """Parse AI JSON response into EconomicWeight objects"""
    try:
        cleaned = raw.strip()
        # Strip markdown fences
        if cleaned.startswith('```json'):
            cleaned = cleaned[7:]
        if cleaned.startswith('```'):
            cleaned = cleaned[3:]
        if cleaned.endswith('```'):
            cleaned = cleaned[:-3]
        cleaned = cleaned.strip()
        
        # Extract JSON object using brace scanning
        if '{' in cleaned:
            start = cleaned.find('{')
            brace = 0
            end = -1
            for i, ch in enumerate(cleaned[start:], start=start):
                if ch == '{':
                    brace += 1
                elif ch == '}':
                    brace -= 1
                    if brace == 0:
                        end = i + 1
                        break
            if end != -1:
                candidate = cleaned[start:end]
            else:
                candidate = cleaned[start:]
        else:
            # Try regex fallback
            m = re.search(r'\{.*\}', cleaned, re.DOTALL)
            if not m:
                raise ValueError('No JSON braces found')
            candidate = m.group(0)
        
        data = json.loads(candidate)
        classes = data.get('classes', []) if isinstance(data, dict) else []
        weights: List[EconomicWeight] = []
        
        for c in classes:
            if not isinstance(c, dict):
                continue
            weights.append(EconomicWeight(
                class_name=_standardize_class_name(c.get('class_name', '')),
                ticker=_clean_ticker_by_trading_status(c.get('ticker', ''), c.get('is_publicly_traded', True)),
                shares_outstanding=c.get('shares_outstanding'),
                economic_weight=None,  # Removed - not needed
                conversion_ratio=c.get('conversion_ratio'),
                votes_per_share=c.get('votes_per_share'),
                source='AI direct query',
                ticker_source=c.get('ticker_source')
            ))
        
        print(f"    üß© Parsed {len(weights)} classes from AI JSON")
        
        # Deduplicate identical class entries
        weights = _deduplicate_classes(weights)
        if len(weights) != len(data.get('classes', [])):
            print(f"    üîß After deduplication: {len(weights)} unique classes")
        
        return weights
        
    except Exception as e:
        print(f"    ‚ùå JSON parse helper failed: {e}")
        print(f"       Raw snippet (first 200 chars): {raw[:200].replace('\n',' ')}...")
        return None

def _deduplicate_classes(weights: List[EconomicWeight]) -> List[EconomicWeight]:
    """Remove duplicate class entries with identical data"""
    if not weights:
        return weights
    
    seen = {}
    deduplicated = []
    
    for weight in weights:
        # Create a key based on class name and key characteristics
        key = (
            weight.class_name,
            weight.ticker,
            weight.shares_outstanding,
            weight.votes_per_share
        )
        
        if key not in seen:
            seen[key] = weight
            deduplicated.append(weight)
        else:
            print(f"    ‚ö†Ô∏è  Removing duplicate class entry: {weight.class_name}")
    
    return deduplicated

def analyze_company_economic_weights(company: Dict[str, Any], ticker_map: Dict[str, str]) -> Dict[str, Any]:
    """Analyze economic weights for a single company using direct AI queries"""
    company_name = company.get('company_name', 'Unknown')
    primary_ticker = company.get('primary_ticker', 'N/A')
    
    print(f"üìä Starting analysis: {company_name} ({primary_ticker})", flush=True)
    
    # Add rate limiting - be respectful to API servers
    time.sleep(0.5)
    
    # Get CIK
    cik = company.get('cik')
    if not cik:
        print(f"  üîç No CIK in data, attempting lookup by name/ticker...", flush=True)
        cik = lookup_cik_by_name_or_ticker(company_name, primary_ticker, ticker_map)
        if cik:
            company['cik'] = cik
            print(f"  ‚úÖ Found CIK via lookup: {cik}", flush=True)
        else:
            print(f"  ‚ùå Could not find CIK for {company_name} ({primary_ticker})", flush=True)
            print(f"  ü§ñ Investigating with AI why no CIK found...", flush=True)
            
            # Use AI to investigate why no CIK - likely delisted/acquired
            investigation = investigate_no_cik_with_ai(company_name, primary_ticker)
            print(f"  üìã AI Investigation: {investigation.get('status')} - {investigation.get('reason')}", flush=True)
            
            # Return special marker for no-CIK companies
            return {
                **company,
                'investigation': investigation,
                'exclude_from_main_output': True
            }
    else:
        print(f"  ‚úÖ Using existing CIK: {cik}", flush=True)
    
    # Query AI directly for economic weights (no SEC filing download)
    print(f"  ü§ñ Querying AI directly for share class data...", flush=True)
    existing_classes = company.get('classes', [])
    weights = query_ai_for_economic_weights(company_name, primary_ticker, cik, existing_classes)
    
    if not weights:
        print(f"  ‚ö†Ô∏è  No economic data extracted by AI for {company_name}")
        return company
    
    # Merge economic data into existing classes array
    updated_classes = []
    existing_classes = company.get('classes', [])
    
    print(f"  üîó Merging AI results with existing voting data...")
    print(f"     ‚Ä¢ AI found: {len(weights)} share classes with economic data")
    print(f"     ‚Ä¢ Existing: {len(existing_classes)} voting classes from input data")

    # Helper: normalize class name to a stable key - more flexible matching
    def _norm_class_name(name: str) -> str:
        if not name:
            return "__unknown__"
        raw_lower = name.lower().strip()
        
        # Handle special patterns for A.O. Smith and similar companies
        if 'class a common' in raw_lower:
            return 'class_a_common'
        if raw_lower in ['common', 'common stock'] or raw_lower.startswith('common:'):
            return 'common_stock'
        
        # Special cases first
        if 'preferred' in raw_lower and 'stock' in raw_lower:
            return 'preferred'
        if 'common stock' in raw_lower and 'class' not in raw_lower:
            return 'common'
        
        # Trim separators and extract core meaning
        short = name.split(':', 1)[0].split(';', 1)[0].split('(', 1)[0]
        s = short.lower().strip()
        # Remove punctuation and extra spaces
        s = re.sub(r"[^a-z0-9\s]", ' ', s)
        s = re.sub(r"\s+", ' ', s).strip()

        # Prefer explicit 'Class X' patterns
        m = re.search(r"\bclass\s*([a-z0-9]+)\b", name.lower())
        if m:
            token = m.group(1)
            if token.isdigit():
                return f"class_num_{token}"
            letter = re.search(r"[a-z]", token)
            if letter:
                return f"class_{letter.group(0).upper()}"
            return f"class_{token}"

        # Single letter patterns
        m2 = re.match(r"^([a-z])\b", s)
        if m2:
            return f"class_{m2.group(1).upper()}"
        
        return s[:60]  # fallback
    
    # Update existing classes with AI-generated economic data
    for weight in weights:
        class_key = _norm_class_name(weight.class_name)
        
        # Look up existing class data
        existing_class = next((c for c in existing_classes if _norm_class_name(c.get('class_name', '')) == class_key), None)
        
        if existing_class:
            print(f"    ‚Ä¢ Found existing class data for {existing_class.get('class_name')}")
            
            # Update with AI-generated data
            existing_class['class_name'] = _standardize_class_name(existing_class.get('class_name', ''))
            existing_class['ticker'] = weight.ticker
            existing_class['shares_outstanding'] = weight.shares_outstanding
            existing_class['conversion_ratio'] = weight.conversion_ratio
            existing_class['votes_per_share'] = weight.votes_per_share
            existing_class['source'] = weight.source
            existing_class['ticker_source'] = weight.ticker_source
            
            updated_classes.append(existing_class)
        else:
            print(f"    ‚Ä¢ No existing data for {weight.class_name}, adding new class")
            # New class entry
            new_class = {
                'class_name': weight.class_name,
                'ticker': weight.ticker,
                'cik': cik,
                'shares_outstanding': weight.shares_outstanding,
                'conversion_ratio': weight.conversion_ratio,
                'votes_per_share': weight.votes_per_share,
                'source': weight.source,
                'ticker_source': weight.ticker_source
            }
            
            updated_classes.append(new_class)
    
    # Update company data
    company['classes'] = updated_classes
    
    return company

# Main processing logic
if __name__ == "__main__":
    print(f"=== Economic Weight Analysis Pipeline (OpenQuestion Mode) ===")
    
    # Load input data
    input_file = 'dual_class_output.json'
    if not os.path.exists(input_file):
        print(f"Error: {input_file} not found. Run 1_dual_class_ingest.py first.")
        # Write minimal output to satisfy pipeline expectation
        output_data = {
            'economic_analysis_date': '2025-09-06',
            'companies_analyzed': 0,
            'successful_analyses': 0,
            'test_mode': False,
            'companies': []
        }
        # Use the test filename as a safe default placeholder
        output_file = 'dual_class_economic_weights_test.json'
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(output_data, f, indent=2, ensure_ascii=False)
        print(f"Wrote empty output to {output_file} due to missing input.")
        sys.exit(1)
    
    with open(input_file, 'r', encoding='utf-8') as f:
        input_data = json.load(f)
    
    # Standardize class names in input data before processing
    companies = input_data.get('companies', [])
    for company in companies:
        classes = company.get('classes', [])
        for cls in classes:
            if 'class_name' in cls:
                cls['class_name'] = _standardize_class_name(cls['class_name'])
    
    test_mode = input_data.get('test_mode', False)
    
    print(f"Loaded {len(companies)} companies from {input_file}")
    print(f"Mode: OpenQuestion (Direct AI queries - no SEC filing downloads)")
    
    # Fetch latest CIK mappings from SEC
    ticker_map = fetch_sec_cik_map()
    
    # Analyze each company
    results = []
    no_cik_companies = []
    
    for company in companies:
        result = analyze_company_economic_weights(company, ticker_map)
        
        # Separate companies without CIKs (likely delisted/acquired)
        if result.get('exclude_from_main_output'):
            no_cik_companies.append(result)
        else:
            results.append(result)
    
    # Prepare main output data (only companies with CIKs)
    output_data = {
        'economic_analysis_date': '2025-09-06',
        'companies_analyzed': len(results),
        'successful_analyses': sum(1 for r in results if r.get('cik')),
        'test_mode': test_mode,
        'companies': results
    }
    
    # Prepare no-CIK output data (delisted/acquired companies)
    no_cik_data = {
        'analysis_date': '2025-09-06',
        'companies_without_cik': len(no_cik_companies),
        'reason': 'Companies likely delisted, acquired, merged, or renamed',
        'companies': no_cik_companies
    }
    
    # Determine output files
    output_file = 'dual_class_economic_weights_test.json' if test_mode else 'dual_class_economic_weights.json'
    no_cik_file = 'no_cik_found_test.json' if test_mode else 'no_cik_found.json'
    
    # Write main output data
    with open(output_file, 'w', encoding='utf-8') as f:
        json.dump(output_data, f, indent=2, ensure_ascii=False)
    
    # Write no-CIK output data if any
    if no_cik_companies:
        with open(no_cik_file, 'w', encoding='utf-8') as f:
            json.dump(no_cik_data, f, indent=2, ensure_ascii=False)
        print(f"üìä {len(no_cik_companies)} companies without CIKs written to {no_cik_file}")
    
    print(f"‚úÖ Analysis complete. {len(results)} companies with CIKs written to {output_file}")
